Description: This Repo aimed in providing toolchain for simulating output result provided by neural network.

Default setting: the default setting of this program will generate 2000*2000 pixel image with different features on it.

Please read the comment in the files to see which parameters are available for changes.

File explanation (By execution sequence): 

    1. Generator.py: Generating the positions, size and rotation angle of all the feature on the simulated map and then draw them out.
    
        Output: GT-testing1.png (the ground truth image)
        
                testing1.png (the high resolution image with artificially added inaccuracy)

        Key functions:

            feature_gen(k, n, r)
                k: how many square regions is the original image to be cut into.
                n: number of target feature
                r: maximum size of the target feature.

            load_feature(feature, shape, target, feature_type)
                feature: a n*3 or n*4 array containing information of the feature, typically generated by feature_gen
                shape: for now we can do 'ellipse' or 'circle', more shapes can be customized
                target: enhance(), real(), or reduce()
                feature type: 'gradient' or None, when choosing None it gives a flat color representation

        Helper functions:
            enhance(): color for fake feature
            real(): color for real feature
            reduce(): color for obstacle

            Returned by those functions are the color and alpha to be used by different features.

                
    2. blurry.py: Taking the two inputs from Generator.py and add salt and pepper noise w/ MODIFIABLE intensity and proportion to testing1.png.
    
        Output: GT-testing1_bw.png (binary map with tells if each pixel belongs to a real target or not)
    
                testing1_blurred.png (Added salt and pepper noise to testing1.png)

        Key functions:
            salt_noisy(image, density=0.04, portion=0.5)
                image: an image opened by cv2
                density: the intensity of the salt and pepper noise, the larger, the more noise
                portion: the number of salt noise vs pepper noise

    
    3. Interpreter.py: Calculating the information within each region(smaller square) and outputting the RAW information map. Also adding the gaussian noise to it.
    
        Output: InfoMap.npy (The information map, an 2D array which contains the information of each region WITHOUT the gaussian noise)
                
                InfoMap_blurred.npy (The information map, an 2D array which contains the information of each region WITH the gaussian noise)
                
                Note: Both of the .npy files take the salt and pepper noise into account and both gives RAW information. Normalization can be made directly on it.

        Key functions:

            calculate_info(index, GT_Img0, n_worker0, boxSize0)
                index: parameter for parallelization
                GT_Img0: the blurred image with all feature that is to be calculated information map
                n_worker0: # of processor to be used
                boxSize0: the edge length in pixel for each information region
                *** Inside this function a formula for calculating information is used. But this formula chan be changed.

                For now, it is in line 31 and looks like this: "val = (loc[2] - (float(loc[0]) + loc[1]) / 2) / 255";
                What it means is:(R-(B+G)/2)/255; More information is available within the file

     
    4. Reconstruct.py: Visualization of the information map. Can be used to compare with the result given by GT-testing_bw.png. We can visually find that we have some ROI being
        hidden and some False positive (FP) start to appear on the product map. This fits exactly with the nature of a typical output from a Neural Network.
     
    5. Normalizer.py: Turn the information map from raw data into NN-like output(0-1 range)
